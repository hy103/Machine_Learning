{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (37500,)\n",
      "shape of test data is (12500,)\n"
     ]
    }
   ],
   "source": [
    "X,y = df['review'].values,df['sentiment'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,stratify=y)\n",
    "print(f'shape of train data is {x_train.shape}')\n",
    "print(f'shape of test data is {x_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']),y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r\"\\s+\", '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\", '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def tockenize(x_train,y_train,x_val,y_val):\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for sent in x_train:\n",
    "        for word in sent.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "  \n",
    "    corpus = Counter(word_list)\n",
    "    # sorting on the basis of most common words\n",
    "    corpus_ = sorted(corpus,key=corpus.get,reverse=True)[:1000]\n",
    "    # creating a dict\n",
    "    onehot_dict = {w:i+1 for i,w in enumerate(corpus_)}\n",
    "    \n",
    "    # tockenize\n",
    "    final_list_train,final_list_test = [],[]\n",
    "    for sent in x_train:\n",
    "            final_list_train.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                     if preprocess_string(word) in onehot_dict.keys()])\n",
    "    for sent in x_val:\n",
    "            final_list_test.append([onehot_dict[preprocess_string(word)] for word in sent.lower().split() \n",
    "                                    if preprocess_string(word) in onehot_dict.keys()])\n",
    "            \n",
    "    encoded_train = [1 if label =='positive' else 0 for label in y_train]  \n",
    "    encoded_test = [1 if label =='positive' else 0 for label in y_val] \n",
    "    return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m4/y98c53d15dg1mt8b2xxsb6s40000gn/T/ipykernel_8032/442953369.py:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(final_list_train), np.array(encoded_train),np.array(final_list_test), np.array(encoded_test),onehot_dict\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,vocab = tockenize(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary is 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Length of vocabulary is {len(vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = padding_(x_train,500)\n",
    "x_test_pad = padding_(x_test,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(x_train_pad), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(x_test_pad), torch.from_numpy(y_test))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 50\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([50, 500])\n",
      "Sample input: \n",
      " tensor([[  0,   0,   0,  ...,  92,  47, 664],\n",
      "        [  0,   0,   0,  ..., 951, 358, 730],\n",
      "        [  0,   0,   0,  ..., 131,  46,  90],\n",
      "        ...,\n",
      "        [  0,   0,   0,  ...,  22,  80,  85],\n",
      "        [  0,   0,   0,  ...,  54, 263,  12],\n",
      "        [  0,   0,   0,  ...,  52, 113, 244]])\n",
      "Sample input: \n",
      " tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
    "        super(SentimentRNN,self).__init__()\n",
    " \n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "        self.no_layers = no_layers\n",
    "        self.vocab_size = vocab_size\n",
    "    \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
    "                           num_layers=no_layers, batch_first=True)\n",
    "        \n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        batch_size = x.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
    "        #print(embeds.shape)  #[50, 500, 1000]\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        \n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim) \n",
    "        \n",
    "        # dropout and fully connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "        \n",
    "        \n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available, CPU used\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(1001, 64)\n",
      "  (lstm): LSTM(64, 256, num_layers=2, batch_first=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "no_layers = 2\n",
    "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
    "embedding_dim = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 256\n",
    "\n",
    "\n",
    "model = SentimentRNN(no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = 5\n",
    "epochs = 5 \n",
    "valid_loss_min = np.Inf\n",
    "# train for some number of epochs\n",
    "epoch_tr_loss,epoch_vl_loss = [],[]\n",
    "epoch_tr_acc,epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    train_acc = 0.0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    h = model.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output,h = model(inputs,h)\n",
    "        \n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        # calculating accuracy\n",
    "        accuracy = acc(output,labels)\n",
    "        train_acc += accuracy\n",
    "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    " \n",
    "    \n",
    "        \n",
    "    val_h = model.init_hidden(batch_size)\n",
    "    val_losses = []\n",
    "    val_acc = 0.0\n",
    "    model.eval()\n",
    "    for inputs, labels in valid_loader:\n",
    "            val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            output, val_h = model(inputs, val_h)\n",
    "            val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            accuracy = acc(output,labels)\n",
    "            val_acc += accuracy\n",
    "            \n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
    "    epoch_val_acc = val_acc/len(valid_loader.dataset)\n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "    epoch_tr_acc.append(epoch_train_acc)\n",
    "    epoch_vl_acc.append(epoch_val_acc)\n",
    "    print(f'Epoch {epoch+1}') \n",
    "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '../working/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n",
    "    print(25*'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_tr_acc, label='Train Acc')\n",
    "plt.plot(epoch_vl_acc, label='Validation Acc')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "    \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_tr_loss, label='Train loss')\n",
    "plt.plot(epoch_vl_loss, label='Validation loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
